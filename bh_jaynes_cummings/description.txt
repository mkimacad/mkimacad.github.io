header:On simulation code (baseline: codes/jaynes_improved.py)
Main parameters at the end (currently line 368 # parameters):
M (number of radiation qubits), N (number of particles in the black hole), reduc (multiplicative factor by which interaction time is reduced).
The codes model the interaction Hamiltonian only, but this is fine since "free Hamiltonians" are irrelevant in interactions here.

header:Digression / some personal vents (1) (added: September 25, 2025): replica wormholes SYK/JT thing.
So I have this very intelligent and well-established and famous faculty member that is way more senior to me. (I am nothing really at this point.)
He gave me wise wisdoms and advices.
However, there are things that I disagree even with a world-class physicist.
At the meeting, I thought I was really dumb, but after recovery, I realized I was not completely dumb.
So I largely forgot about replica wormholes being justified via SYK/JT or eigenstate thermalization hypothesis (ETH).
But he brought this up, and at the time I didn't recall. However, I remembered back why I largely didn't think about it too much.
First of all, of course holographic gravity does not model our reality, which makes things a lot weird, given that his point was that qubit models I am bringing up are not really physics, and I don't have theories that describe the reality, so there is nothing to talk about.
Like yeah, the whole thing about replica wormholes justified via ETH really only makes sense...
$$\textbf{if we can somehow non-gravitationally think that coupling is random or some fine-grained theory is random non-gravitationally.}$$
Now 'you' may say that holographically in the bulk, there is nothing random, so replica wormholes are perfectly good.
But this bulk theory (let's say JT) is very different from what we expect as a bulk black hole theory.
Of course I also use JT in one of my papers to inspire some properties, but this is another level.
If I say replica wormhole holography examples succeed because bulk theories are very different from actual observable black hole bulk theories, would 'you' be outraged.
But that has been the point of many critiques.
$$\textbf{Bulk averaging over geometries at the leading order does not arise in actual observable black hole theories.}$$
Don't get this confuse you - yes, replica wormholes do say that differences from path integrals without replica wormhole become noticeable around Page time. But it is the formulation of the 'gravitational' path integral incorporating replica worhmoles that allows us to calculate the effect size of replica wormholes itself that is questioned here. Within JT, this holds by definition, but would this port in anyway to observable or at least minimally physically plausible black holes?
And this goes all in circle again. If you take the boundary theory instead, then it's $\textbf{a random theory ensemble}$, which is also far from what we expect from the non-gravitational EFT understanding of observable black holes (and $\textbf{far worse}$).
Without further discussions, we could still say ETH does not save replica wormholes, and its problematic effect is visible in parts of the Hilbert space of radiations being inside a black hole.
Which in turn we could say arise from these theories not actually being a model of observable black holes. So we need to go further.
Replica wormholes are $\textbf{unitary}$. $\textbf{But only up to the limit}$, and $\textbf{not proven to be generically unitary}$. That's the case, somewhat as a digression to the paper and rest of the contents here, that I wanted to defend.

header:Digression / some personal vents (2) - continuing from (1), fine-grained entropy or coarse-grained entropy?
Now "you" may say that I have misunderstood the information problem. 
$$\textbf{Yes, the information problem is all about fine-grained entropy.}$$
I get that.
Raju's corrections to mixed state to get pure states are "large corrections", and only "small" in terms of coarse-grained observables.
After all, we need large correction accumulatiosn to generate reverse monotonic entanglement entropy increases, so we would expect large corrections at the end. (Duh!)
The real question, I think, is:
$$\textbf{whether we can initially start from small corrections that can eventually accumulate to large corrections to reverse entanglement entropy increases}$$
which is what Prof. Samir Mathur has been trying to discuss in his small corrections theorem.
There will be large corrections, the question is whether we can start from small corrections and accumulate.
Why small corrections initially? Well, think about ordinary life. $\textbf{We don't have to consult quantum gravity to make good predictions}$.
We expect black holes to be similar initially.
After all, if quantum gravity breaks non-gravitational quantum superpositions by entanglement, then unless quantum mechanics is being modified, then non-gravitational quantum superpositions will be broken, and their effects will be known non-gravitationally.
In the past, we have had this idea of black hole complementarity, but the idea has largely been gone out of fashion. So I will not speak of it.
This is why we are talking of fine-grained entropy even if we seem to be discussing coarse-grained entropy in the small corrections theorem.
Because:
$$\textbf{it is really hard to break pure non-gravitational superpositions by quantum gravity effects without any effect on coarse-grained non-gravitational states.}$$
If we expect semiclassical no drama pictures to be maintained down to full evaporation, we should be able to discuss in terms of coarse-grained states and how they are corrected over time due to quantum gravity effects.
By the way, the "extended" small corrections theorem exactly goes over this issue - does the full fine-grained state change the theorem? The answer in the theorem was no, as long as the conventional semiclassical picture is assumed.
Now again, the "wise man" would say that people like Prof. Pennington has done hundreds of thousands of calculations more than I ever did so I should not just deduce his thoughts from what is publically available.
However, I do think that this coarse-grained thing is what he had in mind when he was debating with Prof. Suvrat Raju. Both sides have not seemed to get their points, but I think I do.

header:Continuing digression (2), but the punch line
The debate should really be:
$$\textbf{is it possible in theory for an observer to collect all radiations and verify purity of radiations?}$$
If we can, then we can describe in terms of fine-grained corrections to coarse-grained states. (Prof. Pennington and for this matter, Prof. Mathur)
If we cannot, then the small corrections theorem does not even make sense. (the 'wise man' and possibly Prof. Raju)
Unless this question is properly addressed (and I think the latter camp refuses to acknowledge that this question even matters), no progress can be made.
Obviously, as you can notice I am in the first camp, and I think it is a conservative option.
We just asking for entropy here. How can quantum gravity induce large entropy changes and yet not leave their marks on non-gravitational observables?
And it makes sense to ask whether holography of information can be consistent with the first no drama vision, at least I think.
But the conversation becomes really difficult, because the other camp does not acknowledge relevance of the question itself.
"that you are not doing physics" makes zero contribution, and this mode of arguments actually allows for detractors outside to say "oh physics is no longer interested in modeling the reality".
Because you are forcing physics calculations to be about something very distant from modeling the reality, when we should have more talks about whether this ever gets to have relevance in modeling our reality and what we mean by that.
"You" may say that this is philosophy, not physics, but screw all that. Let's just try to think about the real world and do whatever we need, whether that may seem to be philosophy or physics, I wish we do not care so much about that.

The fun thing is that different people belong to different "camps" when asked different questions - this is normal, but variance is much more than what the field itself seems to realize overall.
One physicist may be on the replica wormhole camp but also believe that in theory, observing all radiations can produce a purification result.
Another physicist may defend replica wormholes but believe that coarse-grained observables will not solve the information problem, and we have to make fine-grained calculations.

So my plea is: please recognize that variance is much greater than you realize.
The black hole information problem is not resolved partly because of this variance.

And no, I do not claim here that I resolved the information problem.
I may be slightly interested in resolving it. But I am not "trying" to resolve it here.
The wise man would say that I am trying to resolve the information problem.

Maybe one day, after doing hard works and very basic contributions that go neglected by all these wise people, I may be able to resolve it.
I do not expect it, and I just wish these wise men can be more thankful of basic stuffs that students contribute today.
No arrogance. It's all we hope for.
The world is better run by millions of those better-than-average people than just few genius guys, and science is no exception.
I just wish this is more recognized before charging that some person is trying to resolve great wonders of the world. Anyway.

header:History (date-wise)
Paper V1/github.io description: May 25-31, 2025
A memo on the necessity of gravity quantization, forked to https://mkimacad.github.io/gravity_quantization: May 31-June 2, 2025
Significantly revised the github.io description, correcting an initially misleading explanation: June 3, 2025 
header:The main goal of this paper
1) Show that semiclassical spacetime geometry can be consistent with the Page curve,
2) the problem with the small corrections theorem + firewall paradox has to do with empty black hole quantum branches in superpositions.
It is easy to achieve unitarity by violating semiclassical spacetime. Satisfying both goals is what makes the matter difficult. The paper succeeds.
(No-hair, no electricity, no angular momentum -> semiclassical geometry = semiclassical black hole mass (equivalently, energy).)
In this Jaynes-Cummings (JCM) model, black hole=(optical) cavity=field, (Hawking) radiations=atom=qubits. $\hslash=1$ is used for convenience.
header:On "time" in this modified Jaynes-Cummings (JCM) model
Qubits are not fundamental - they are only entropy/entanglement generators. Time can conveniently be re-scaled to fit the Page curve slopes.
header:General storylines
1. Non-interaction energy is conserved. Qubits are initialized with no energy to transfer to the black hole. The black hole probabilistically emits energy via JCM interaction until it reaches its ground state, thereby being purified - unitarity upheld even after complete evaporation.
2. Meanwhile, with small interaction time, semiclassical spacetime geometry with close to zero variance (via central limit theorem + very low variance of each qubit) can be maintained - semiclassical spacetime preserved.
3. This qudit model is almost identical to the toy qubit setup used in black hole physics.
4. The real issue with the black hole information problem is that semiclassical spacetime is often thought to imply that the empty black hole quantum branch of superpositions can be ignored. But contributions of this branch eventually build up, despite semiclassical spacetime. Without the energy lower bound of the black hole, black hole entanglement entropy builds up continuously even in this model.
5. Nothing wrong with EFT: complete evaporation or not, different horizon vacua. The black hole exterior sees nothing strange (horizon vacuum maintained).
6. AMPS firewall and the small corrections theorem went astray because infalling observers do not see the interior horizon vacuum, though they sort of do for each classically measured state $|n\rangle$.
header:JCM interaction setup
1. The JCM interaction (between one qubit and the black hole) of the model says: if a two-energy radiation qubit is in ground state $|0\rangle$ and the black hole has enegy, then the qubit should gain energy to the excited state. If the qubit is in excited state $|1\rangle$ then the black hole should gain energy. Our initial qubit state is always in $|0\rangle$, so the black hole always loses energy until complete evaporation. Governed by $H_I$.
2. Each $k$th qubit, initially in $|0\rangle$ interacts sequentially with the black hole for duration of $\Delta t_k$ ("interaction time"). Then the qubit flies away, never interacting with the black hole again.
3. The initial state of the black hole at $t=0$ is $|N\rangle$, with $a^{\dagger}a|N\rangle = N|N\rangle$, $N \in \mathbb{N}$. The pre-interaction state of a qubit is $|0\rangle$ as aforementioned.
$$H_{rad} = \omega_a |1\rangle\langle 1|$$
$$H_{BH} = \omega_a a^{\dagger}a$$
with $[a,a^{\dagger}]=1$ and $[a,a]=[a^{\dagger},a^{\dagger}]=0$. 
$$H_I = g(|1\rangle\langle 0|a + |0\rangle \langle 1|a^{\dagger})$$
$g$ and $\omega_a$ are largely irrelevant in this paper.
header:Models/cases considered
Variable interaction time case: $\Delta t_k$ is determined by $\langle n \rangle$, the average excitation number of the black hole.
Fixed interaction time case: $\Delta t_k$ is determined by $N$, the initial particle number of the black hole.
Interaction time reduction: $\Delta t_k$ can be reduced by $k_r$ (reduc in the codes) to better induce semiclassicality of spacetime.
Simplified model: Replacing JCM interaction with a more simplified interaction unitary $U$ - for all $|n\rangle$ ($n\in \mathbb{N}$) of the black hole, same entanglement behavior except for $n=0$ (no entanglement).
header:Simulation results
The model simulations go as follows:
img:imgs/nosimple_ex1_1.png
img:imgs/nosimple_ex1_2.png
img:imgs/nosimple_ex2_1.png
img:imgs/nosimple_ex2_2.png
img:imgs/reduced_time_ex1_1.png
img:imgs/reduced_time_ex1_2.png
We confirm the same qualitative result for the simplified model:
img:imgs/simple_ex1.png
img:imgs/simple_ex2.png
header:On necessity of quantum gravity (possibly in v2 of the paper, or a separate paper)
See https://mkimacad.github.io/gravity_quantization as the main reference: the JCM model of this paper could be thought of as a thought experiment in the necessity of quantum gravity.
header:Is this a consequence of no hair? (possibly in v2 of the paper)
Sort of yes. If we had degenerate (ie. multiple) ground states, then entanglement entropy could be much larger at late times. So apparently, no hair actually helps us to solve the information problem. (Analyzing the case of degenerate ground states is also a wonderful future topic.)
header:On weirdness of semiclassicality (possibly in v2 of the paper, replacing the previously misleading explanation in this github.io page, though not the paper)
A significant reason why we have so many problems understanding black holes being roughly semiclassical is that entropy decreases due to effects of the empty black hole branch, but the significance of the empty black hole branch seems to instead suggest high energy variance "classically". It is this classical intuition that is wrong in quantum mechanics due to quantum correlations. (Inevitability of entropy and energy variance decreases can be seen from the fact that the number of available black hole microstates decreases significantly at late times.)
The picture we have is that at early times, the central limit theorem (CLT) dominates such that we can add up normal distributions of sub-intervals. As the direction of entropy reverses at late times, this CLT picture no longer holds and variance is actually lower than the maximum variance reached at early times. (Recall that our outcomes and eigenstates are all energy eigenstates. So entropy variance is tied to energy variance.) So as the black hole evaporates, deviations from complete semiclassicality are suppressed enough to assure the validity of the semiclassical picture.
(Note that at early times, Var(X+Y) = Var(X)+Var(Y)+2Cov(X,Y), but the covariance part can be ignored since the entanglement structure does not change much from one interval to another.)
header:The JCM model 'models' absorption as well (not in the paper, nor needed, but possibly in v2)
If a qubit is initialized in $|1\rangle$, then we have the black hole absorbing energy on average instead (the black hole attracts matter-energy), later releasing it back once other qubits are mostly on $|0\rangle$.
header:On temperature-based re-scaling of interaction time and abrupt vacuum change (possibly in v2 of the paper)
While this paper scales interaction time quasi-uniformly, we can adjust interaction time such that it varies with the semiclassical temperature of the black hole. As the black hole becomes smaller, temperature increases, which leads to an abrupt vacuum change right before or after complete evaporation, unless we believe in final remnants. Therefore, a potential counter-argument that the abrupt 'vacuum change' does not arise cannot hold. There is no smooth tranisition to the approximately flat-space horizon. This is a well-understood and established point, so should not be controversial, and indeed the necessity of this abrupt change without remnants has inspired some to accept remnants instead.
header:Extra talks: replica wormholes and Hilbert space factorization (not in the paper)
There could also be workarounds that minimize the partial breakdown of semiclassicality. Essentially, the issue is that the black hole does not exist for some quantum branches, so these branches need to be taken out to the exterior, if we are following the traditional qubit pair picture. This may be achieved by the ideas like replica wormholes - see discussions in https://mkimacad.github.io/braneworld , though note that in https://doi.org/10.1016/j.physletb.2024.139130 , Khodahami and Azizi (2024) argues that firewalls can be generated with replica wormholes. If this holds generally, the interior horizon vacuum is not really saved.
Portraying the empty black hole outcome in a superposition within the black hole interior locally is impossible unless some degrees of freedom that were previously assumed to exist is discarded. This effectively causes the EFT Hilbert space to change, along with its factorization. The JCM model did not require such a change, because we are not too concerned with the local reprsentation of the interior. The Hilbert space factorization issue is therefore not an artefact of Karch-Randall braneworld and is definitely not restricted to gauge theories.
header:Some trivial matters: Initial "cavity"/black hole state choice
In this paper $|N\rangle$ is chosen as an initial state. We can go more realistically and choose a 'Gaussian' state of different excitation states (which fits a semiclassical state better) without much difference.
header:Do we need to replicate the Page curve, given holography of information?
See discussions in https://mkimacad.github.io/braneworld , but some of them are replicated here. In short, confirmation by our familiar local non-gravitational horizon observables is important. Holography of information can be or is correct, but there may still be pathologies around black hole horizons that require understanding. We cannot simply invoke unitarity of quantum physics or AdS/CFT to resolve the information problem, and this is essentially the same thing.
header:Is black hole complementarity or a special 'boundary of a boundary' setup like Karch-Randall braneworld necessary?
No. But they provide convenient ways of directly connecting to quantum gravity calculations.
header:Digression: "remnants" of incomplete fragments that may become relevant
(Also quantization issues, if we do not properly correct states. Complications after complications. It does not seem like these complications are just for black hole setups.)
(And the JCM model of this paper also makes us the very condition of classicality within large-n classicality, but I will stop here for now.)
header: Addendum
Currently working toward V2.B that incorporates parts of the braneworld paper as well that is to be uploaded to arXiv. 
