header:Descriptions forthcoming but meanwhile some reflections
Yep. And I am moving because it just seems that I cannot find any space in the current university.
So if any graduate school wishes to pick me up as their phd student (in today's time, I know this is not how things mostly work, but):
please contact me via email (mkimacad@gmail.com).
And will need to update descriptions here, but for now need some time adjusting. So the below is just reflections, not proper descriptions.
header:1) Classicality.
WARNING: This is actually nothing directly related to the papers below.
The problem I had with the conventional story about emergence of classicality, and the one I struggled with, is the question of variance.
We all know that the quantum state of our macroscopic world is definitely not a coherent state.
Now we are all told this story about quantum harmonic oscillators being able to approximate our world locally.
But that does not license us to think that quantum states are coherent states.
What the above story does, when we justify classical mechanics, is the incoherent dance between harmonic oscillator models and classical mechanical worlds.
If we are describing some perturbations to the classical harmonic oscillator world for the ideal classical world, then we are probably fine using coherent states.
But we have classical mechanics as dynamics to justify from quantum physics, which means the world is already outside the domain of harmonic oscillators.
Locally and in static and kinematics sense, this may work. Not really so as dynamics.
And even when we accept the quantum harmonic oscillator picture, why particularly coherent states?
The classical world is supposed to be emergent, not reliant on some microscopic state being `correct'.

But aren't we guaranteed that on average, classical mechanics hold from quantum mechanics? 
Yes.
But this is not enough. Think of this way. A heavily localized state will have large variance on momentum.
A classical state features small variance on both momentum and position.
Now you can rely on the average, but the problem is that momentum add up, not average out. So variance actually increases.
Basic statistics, assuming no covariance between random variables:
$$Var(\sum_k a_kX_k) = \sum_k a_k^2 Var(X_k)$$
On average, if we set $a_k=1/n$ then variance goes by $1/n$ (coefficient-wise $1/n^2$) so the variance will continue to drop by averaging.
But this is about total momentum. For position, we should be looking at distance away from the average position.
While the average position stabilizes as $n \to \infty$, this variance stabilizes to a non-finite value trivially (if you know stat). So we are in trouble.
Start from a low single-particle position variance and have a problem in momentum.
Start from a large single-particle position variance and position variance never disappears.
It is this question of variance that troubled me significantly, and I have been puzzled...
Until now.

What I have in mind now is what other people may initially think as already known - the environment consistently measuring some quantum state such that classicality holds path-wise if we zoom out enough. 
Now there are some problems with this idea - it relies on quantum measurements.. which probably should be explained by properly identifying the classical domain anyway. So we are sorting of explaining things by the ones that are in need of an explanations.
As somehow the classical world emerges, supposedly non-unitary quantum measurements are automatically being done according to the aforementioned explanation..
Which is so wrong.
This issue is now less of a problem if there does exists a unitary account of quantum measurements, and in fact in case such an account exists, we can outline when a quantum world becomes visible to the classical world classically and remains largely invisible.

header:2) Trivia
A) I think Ted Jacobson's thermodynamic spacetime 'sort of' foreshadowed this ensemble theory approach to quantum gravity - he got it for wrong reasons, though.
This casts general relativity as an ensemble reflection - in normal times, GR is correct, but for black holes, GR might be wrong.
Except GR being wrong is yet to be supported, so a more reasonable idea would be the one I propose in my paper.

B) If you think about energy conservation in quantum mechanics, it actually sort of breaks down whenever measurements are done. Where does that energy and its variaton go? Maybe quantum gravity has an answer for this, and it would be correct.

C) If (quantum) EFT breaks down as is necessary for islands/replica wormholes, then most analysis about massive gravitons in islands/replica wormholes break down.
You need more than EFT analysis - a full string-theoretic analysis is required. I do not think anyone has done that satisfactorily.

header: 3) An ensemble theory is a sort-of psi-epistemic theory. Doesn't it provide some shortcuts?
Of course this only makes sense if one does accept some theory to be an ensemble theory.
But if this is accepted, then an ensemble theory is sort-of a psi-epistemic theory.
I can claim that because an ensemble theory is only an effective theory, no more than one knowledge (epistemic) state ever maps to the same ontic reality.
(Instead, it's more that multiple actual states map to the same effective coarse-grained knowledge state.)
But what if an ensemble theory is taken too far, we add `non-perturbative' corrections and so forth?
Then it would be difficult not to go in conflict with psi-ontology theorems.
By adding non-perturbative corrections, either one do not believe in an 'ensemble' theory, or something else.

header: 4) We do not need another measurement theory. We already have one.
Context - right after the AMPS firewall paper. Firewalls requiring a new measurement theory and all that. But really, firewalls already have their measurement theory inherently. So no need for that. The Born rule is safe in a unitary fashion. Unless you need to collapse quantum states immediately.

header: 5) Everyone should have a renewed interest in quantum computing!
JT/RMT -> now effective postselection feasible if we can figure out the right theory out of the ensemble. But the quantum computation that this right theory does cannot be replaced by classical computing. Massive advantage.

header: 6) Discreteness of string theory
The results of this paper partially come from discrete aspects of string theory (eg. discrete symmetry) that normally does not appear in quantum field theory.

header: 7) Some trivia.
Lately (December, 2025), I discovered a series of papers by Alexey Kryukov via philsci-archive. The paper contents actually differ from this paper despite initial illusions of similarity.
From what I understand, Kryukov's papers attempt to derive the Born rule from the (prior) normal distribution on minimum-uncertainty quasi-classical states.
Of course this is with the assumption that transition probability somewhat relates to some distance measure.
And then Kryukov finds that the Born rule is the only consistent one.
The results are beautiful, though in a way this is largely a result of the powerful assumption that transition probability relates to some distance measure, and that part is the one hard to justify in purely physical terms.
The normal distribution prior can be justified as a random walk of a particle approximating a Brownian motion, whch supposedly resembles the classical analog of a measurement process, with random Hamiltonians picked from a Gaussian Hamiltonian ensemble.
(Kryukov also proves that the Schrodinger equation collapses to classical mechanics whenever evolution is restricted to the classical state manifold.
That proof works mostly as: when the "wavepacket spread" part is removed, we can obtain classical mechanics from quantum mechanics.)

